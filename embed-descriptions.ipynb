{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections.abc import Mapping\n",
    "\n",
    "docs = []\n",
    "\n",
    "with open('request-docs_results.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        try:\n",
    "            response = json.loads(line)[1][\"choices\"][0][\"message\"][\"content\"]\n",
    "            metadata = json.loads(line)[2]\n",
    "        except KeyError as ke:\n",
    "            print(\"KeyError: \", ke)\n",
    "            continue\n",
    "        except IndexError as ie:\n",
    "            print(\"IndexError: \", ie)\n",
    "            continue\n",
    "        if not isinstance(response, str):\n",
    "            continue\n",
    "        if not isinstance(metadata, Mapping):\n",
    "            continue\n",
    "        doc = {\n",
    "            \"model\": \"text-embedding-ada-002\", \n",
    "            \"input\": response,\n",
    "            \"metadata\": metadata\n",
    "        }\n",
    "        docs.append(doc)\n",
    "        \n",
    "with open('request-docs-embedding.jsonl', 'w') as f:\n",
    "    for doc in docs:\n",
    "        f.write(json.dumps(doc) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections.abc import Mapping\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from typing import List\n",
    "\n",
    "UNIQUE_KEY = \"property_id\"\n",
    "\n",
    "df = pd.read_csv('small_df.csv', parse_dates=[\"date_added\"])\n",
    "\n",
    "with open('request-docs-embedding_results.jsonl', 'r') as f1, open(\"complete-data.jsonl\", \"w\") as f2:\n",
    "    for line in f1:\n",
    "        try:\n",
    "            request = json.loads(line)[0][\"input\"]\n",
    "            response = json.loads(line)[1][\"data\"][0][\"embedding\"]\n",
    "            unique_key = json.loads(line)[2][\"row_id\"]\n",
    "        except KeyError as ke:\n",
    "            print(\"KeyError: \", ke)\n",
    "            continue\n",
    "        except IndexError as ie:\n",
    "            print(\"IndexError: \", ie)\n",
    "            continue\n",
    "        if not isinstance(response, List):\n",
    "            continue\n",
    "        if not isinstance(unique_key, int):\n",
    "            continue\n",
    "        if not isinstance(request, str):\n",
    "            continue\n",
    "        \n",
    "        doc = {}\n",
    "        doc[\"GPT-Description\"] = request\n",
    "        doc[\"Ada-Embedding\"] = response\n",
    "        \n",
    "        data = df[df[UNIQUE_KEY] == unique_key].to_json(orient=\"records\", lines=True, date_format=\"iso\")\n",
    "        data = json.loads(data)\n",
    "        doc.update(data)\n",
    "        \n",
    "        for key in (\"_agency\", \"agency_id\", \"_agent\", \"agent_id\", \"amenities\"):\n",
    "            doc.pop(key)\n",
    "        \n",
    "        f2.write(json.dumps(doc) + '\\n')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/konrad/code/fun/nlp-housing/.venv/lib/python3.9/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import Database\n",
    "from Database import CollectionWrapper\n",
    "import importlib \n",
    "importlib.reload(Database)\n",
    "\n",
    "col = CollectionWrapper()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "UNIQUE_KEY = \"property_id\"\n",
    "from pprint import pprint\n",
    "from typing import List\n",
    "\n",
    "def chunks(iterable, batch_size=100):\n",
    "    \"\"\"A helper function to break an iterable into chunks of size batch_size.\"\"\"\n",
    "    it = iter(iterable)\n",
    "    chunk = tuple(itertools.islice(it, batch_size))\n",
    "    while chunk:\n",
    "        yield chunk\n",
    "        chunk = tuple(itertools.islice(it, batch_size))\n",
    "        \n",
    "def generate_entry(path):\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            doc =  json.loads(line)\n",
    "            rest_of_data = doc.copy()\n",
    "            for key in (\"Ada-Embedding\", UNIQUE_KEY):\n",
    "                rest_of_data.pop(key)\n",
    "            if not isinstance(doc[UNIQUE_KEY], int):\n",
    "                continue\n",
    "            if not isinstance(doc[\"Ada-Embedding\"], list):\n",
    "                continue\n",
    "            if len(doc[\"Ada-Embedding\"]) != 1536:\n",
    "                continue\n",
    "            result = (\n",
    "                str(doc[UNIQUE_KEY]),\n",
    "                doc[\"Ada-Embedding\"],\n",
    "                rest_of_data\n",
    "            )\n",
    "            yield result\n",
    "\n",
    "\n",
    "async_results = [\n",
    "    col._index.upsert(vectors=ids_vectors_chunk, async_req=True)\n",
    "    for ids_vectors_chunk in chunks(generate_entry(\"/Users/konrad/code/fun/nlp-housing/data/complete-data.jsonl\"), 100)\n",
    "]\n",
    "# Wait for and retrieve responses (this raises in case of error)\n",
    "[async_result.get() for async_result in async_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
